{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Title : Natural Language Processing with Disaster Tweets","metadata":{}},{"cell_type":"markdown","source":"Twitter has become an important communication channel in times of emergency.\nThe ubiquitousness of smartphones enables people to announce an emergency they’re observing in real-time. Because of this, more agencies are interested in programatically monitoring Twitter (i.e. disaster relief organizations and news agencies).\n\nBut, it’s not always clear whether a person’s words are actually announcing a disaster.\n\nThe author explicitly uses the word “ABLAZE” but means it metaphorically. This is clear to a human right away, especially with the visual aid. But it’s less clear to a machine.\n\nIn this competition, you’re challenged to build a machine learning model that predicts which Tweets are about real disasters and which one’s aren’t. You’ll have access to a dataset of 10,000 tweets that were hand classified. If this is your first time working on an NLP problem, we've created a quick tutorial to get you up and running.","metadata":{}},{"cell_type":"markdown","source":"# 2. Importing required Libraries","metadata":{}},{"cell_type":"markdown","source":"Using TensorFlow backend.","metadata":{}},{"cell_type":"code","source":"import re\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport nltk\nfrom nltk.corpus import stopwords \n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport keras\nfrom keras.initializers import Constant\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras import layers, Sequential\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.layers import LSTM","metadata":{"ExecuteTime":{"end_time":"2022-07-18T14:59:28.909459Z","start_time":"2022-07-18T14:59:28.896498Z"},"execution":{"iopub.status.busy":"2022-07-19T15:15:13.818226Z","iopub.execute_input":"2022-07-19T15:15:13.821153Z","iopub.status.idle":"2022-07-19T15:15:26.559887Z","shell.execute_reply.started":"2022-07-19T15:15:13.820958Z","shell.execute_reply":"2022-07-19T15:15:26.558994Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# 3. Loading the data","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv('../input/nlp-getting-started/train.csv', dtype={'id': np.int16, 'target': np.int16})\ntest_data = pd.read_csv('../input/nlp-getting-started/test.csv', dtype={'id': np.int16})","metadata":{"ExecuteTime":{"end_time":"2022-07-18T14:01:03.634670Z","start_time":"2022-07-18T14:01:03.602197Z"},"execution":{"iopub.status.busy":"2022-07-19T15:15:26.561873Z","iopub.execute_input":"2022-07-19T15:15:26.562753Z","iopub.status.idle":"2022-07-19T15:15:26.641424Z","shell.execute_reply.started":"2022-07-19T15:15:26.562720Z","shell.execute_reply":"2022-07-19T15:15:26.640376Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# 4. EDA","metadata":{}},{"cell_type":"markdown","source":"**1) Check missing values**","metadata":{}},{"cell_type":"code","source":"train_data.isnull().sum()","metadata":{"ExecuteTime":{"end_time":"2022-07-18T14:01:03.893294Z","start_time":"2022-07-18T14:01:03.882324Z"},"execution":{"iopub.status.busy":"2022-07-19T15:15:26.644452Z","iopub.execute_input":"2022-07-19T15:15:26.645250Z","iopub.status.idle":"2022-07-19T15:15:26.669045Z","shell.execute_reply.started":"2022-07-19T15:15:26.645206Z","shell.execute_reply":"2022-07-19T15:15:26.667850Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"Missing values exist in the keyword, location variables.","metadata":{}},{"cell_type":"code","source":"miss_cols = ['keyword', 'location']\n\nfig, axes = plt.subplots(2,figsize=(10, 15))\n\nsns.barplot(x=train_data[miss_cols].isnull().sum().index, y=train_data[miss_cols].isnull().sum().values, ax=axes[0])\nsns.barplot(x=train_data[miss_cols].isnull().sum().index, y=train_data[miss_cols].isnull().sum().values, ax=axes[1])\n\naxes[0].set_ylabel('Missing Count', size=15, labelpad=20)\naxes[0].tick_params(axis='x', labelsize=15)\naxes[0].tick_params(axis='y', labelsize=15)\naxes[1].set_ylabel('Missing Count', size=15, labelpad=20)\naxes[1].tick_params(axis='x', labelsize=15)\naxes[1].tick_params(axis='y', labelsize=15)\n\naxes[0].set_title('Train data', fontsize=15)\naxes[1].set_title('Test data', fontsize=15)\n\nplt.show()","metadata":{"ExecuteTime":{"end_time":"2022-07-18T14:01:04.631214Z","start_time":"2022-07-18T14:01:04.418807Z"},"execution":{"iopub.status.busy":"2022-07-19T15:15:26.672825Z","iopub.execute_input":"2022-07-19T15:15:26.673566Z","iopub.status.idle":"2022-07-19T15:15:27.036539Z","shell.execute_reply.started":"2022-07-19T15:15:26.673520Z","shell.execute_reply":"2022-07-19T15:15:27.035383Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"LOCATION variable has many missing values.","metadata":{}},{"cell_type":"code","source":"train_data.groupby('target').count()['id']","metadata":{"ExecuteTime":{"end_time":"2022-07-18T14:01:04.149724Z","start_time":"2022-07-18T14:01:04.129748Z"},"execution":{"iopub.status.busy":"2022-07-19T15:15:27.038278Z","iopub.execute_input":"2022-07-19T15:15:27.039029Z","iopub.status.idle":"2022-07-19T15:15:27.055814Z","shell.execute_reply.started":"2022-07-19T15:15:27.038984Z","shell.execute_reply":"2022-07-19T15:15:27.054362Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"There are more tweets with class 0 ( No disaster) than class 1 ( disaster tweets)","metadata":{}},{"cell_type":"code","source":"train_x = train_data['text'].copy()\ntrain_y = train_data['target'].copy()","metadata":{"ExecuteTime":{"end_time":"2022-07-18T13:54:01.149105Z","start_time":"2022-07-18T13:54:01.139132Z"},"execution":{"iopub.status.busy":"2022-07-19T15:15:27.057490Z","iopub.execute_input":"2022-07-19T15:15:27.058351Z","iopub.status.idle":"2022-07-19T15:15:27.064356Z","shell.execute_reply.started":"2022-07-19T15:15:27.058314Z","shell.execute_reply":"2022-07-19T15:15:27.063143Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"0 is more than 1, but it is not much different.","metadata":{}},{"cell_type":"markdown","source":"**2) Data Cleaning**","metadata":{}},{"cell_type":"markdown","source":"Missing values must be processed before data analysis can be performed.","metadata":{}},{"cell_type":"code","source":"stop = stopwords.words('english')\ndef clean(text):\n    \n    text = re.sub(r'http\\S+', ' ', text)\n    \n    text = re.sub(r'<.*?>', ' ', text)    \n    \n    text = re.sub(r'#\\w+', ' ', text)    \n     \n    text = re.sub(r'@\\w+', ' ', text)\n    \n    text = re.sub(r'\\d+', ' ', text)\n    \n    text = text.split()\n    \n    text = ' '.join([word for word in text if word not in stop])\n    \n    return text","metadata":{"ExecuteTime":{"end_time":"2022-07-18T14:06:46.385311Z","start_time":"2022-07-18T14:06:46.366362Z"},"execution":{"iopub.status.busy":"2022-07-19T15:15:55.959081Z","iopub.execute_input":"2022-07-19T15:15:55.959423Z","iopub.status.idle":"2022-07-19T15:15:55.982473Z","shell.execute_reply.started":"2022-07-19T15:15:55.959395Z","shell.execute_reply":"2022-07-19T15:15:55.981375Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Removing Stop words","metadata":{}},{"cell_type":"code","source":"train_x_cleaned = train_x.apply(clean)\ntrain_x_cleaned.head()","metadata":{"ExecuteTime":{"end_time":"2022-07-18T14:06:47.100399Z","start_time":"2022-07-18T14:06:46.649603Z"},"execution":{"iopub.status.busy":"2022-07-19T15:15:55.983899Z","iopub.execute_input":"2022-07-19T15:15:55.984565Z","iopub.status.idle":"2022-07-19T15:15:56.333014Z","shell.execute_reply.started":"2022-07-19T15:15:55.984529Z","shell.execute_reply":"2022-07-19T15:15:56.331870Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Max Length","metadata":{}},{"cell_type":"code","source":"max_len = max(train_x_cleaned.apply(len))\nprint('max length: {}'.format(max_len))","metadata":{"ExecuteTime":{"end_time":"2022-07-18T14:06:47.269945Z","start_time":"2022-07-18T14:06:47.249999Z"},"execution":{"iopub.status.busy":"2022-07-19T15:15:56.337100Z","iopub.execute_input":"2022-07-19T15:15:56.337435Z","iopub.status.idle":"2022-07-19T15:15:56.351558Z","shell.execute_reply.started":"2022-07-19T15:15:56.337406Z","shell.execute_reply":"2022-07-19T15:15:56.350265Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"**3) Tokenize**","metadata":{}},{"cell_type":"markdown","source":"the text must be vectorized by generating a sequence of specified lengths for each tweet in the dataset. \nUsing the Keras Tokenizer","metadata":{}},{"cell_type":"code","source":"tokenizer = Tokenizer()\ntokenizer.fit_on_texts(train_x_cleaned)\nvocab_size = len(tokenizer.word_index) + 1\nx = tokenizer.texts_to_sequences(train_x_cleaned)\nx = pad_sequences(x, max_len, padding='post')\ny = train_y\nprint('train_x_clean:', train_x_cleaned[4])\nprint('*'*50)\nprint('x:',x[5])\nprint('vocabulary size:{}'.format(vocab_size))","metadata":{"ExecuteTime":{"end_time":"2022-07-18T14:10:23.133600Z","start_time":"2022-07-18T14:10:22.603020Z"},"execution":{"iopub.status.busy":"2022-07-19T15:15:56.353233Z","iopub.execute_input":"2022-07-19T15:15:56.353723Z","iopub.status.idle":"2022-07-19T15:15:57.390822Z","shell.execute_reply.started":"2022-07-19T15:15:56.353689Z","shell.execute_reply":"2022-07-19T15:15:57.389363Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"x.shape","metadata":{"ExecuteTime":{"end_time":"2022-07-18T14:10:23.179476Z","start_time":"2022-07-18T14:10:23.166512Z"},"execution":{"iopub.status.busy":"2022-07-19T15:15:57.392401Z","iopub.execute_input":"2022-07-19T15:15:57.392755Z","iopub.status.idle":"2022-07-19T15:15:57.400704Z","shell.execute_reply.started":"2022-07-19T15:15:57.392724Z","shell.execute_reply":"2022-07-19T15:15:57.399324Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"y.shape","metadata":{"ExecuteTime":{"end_time":"2022-07-18T14:10:23.255273Z","start_time":"2022-07-18T14:10:23.250287Z"},"execution":{"iopub.status.busy":"2022-07-19T15:15:57.402759Z","iopub.execute_input":"2022-07-19T15:15:57.404156Z","iopub.status.idle":"2022-07-19T15:15:57.412572Z","shell.execute_reply.started":"2022-07-19T15:15:57.404107Z","shell.execute_reply":"2022-07-19T15:15:57.411669Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# 5. Create Models","metadata":{}},{"cell_type":"markdown","source":"**model 1**","metadata":{}},{"cell_type":"markdown","source":"GRU implementation with basic embedding layer","metadata":{}},{"cell_type":"code","source":"epoch_size =10\nbatch_size = 32\nembedding_dim = 16\noptimizer = optimizers.Adam(lr=3e-4)\n\nmodel = Sequential([\n    layers.Embedding(vocab_size, embedding_dim, input_length=max_len),\n    layers.Bidirectional(layers.GRU(256, return_sequences=True)),\n    layers.GlobalMaxPool1D(),\n#     layers.Dense(128, activation='relu'),\n#     layers.Dropout(0.4),\n    layers.Dense(64, activation='relu'),\n    layers.Dropout(0.4),\n    layers.Dense(2, activation='sigmoid')\n])\nmodel.summary()","metadata":{"ExecuteTime":{"end_time":"2022-07-18T14:10:24.883919Z","start_time":"2022-07-18T14:10:24.250613Z"},"execution":{"iopub.status.busy":"2022-07-19T15:15:57.413801Z","iopub.execute_input":"2022-07-19T15:15:57.414919Z","iopub.status.idle":"2022-07-19T15:15:58.112872Z","shell.execute_reply.started":"2022-07-19T15:15:57.414869Z","shell.execute_reply":"2022-07-19T15:15:58.111734Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"training the model","metadata":{}},{"cell_type":"code","source":"model.compile(loss='sparse_categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])\nhistory = model.fit(x, y, epochs=epoch_size, validation_split=0.1)","metadata":{"ExecuteTime":{"end_time":"2022-07-18T14:25:21.762141Z","start_time":"2022-07-18T14:14:55.754452Z"},"execution":{"iopub.status.busy":"2022-07-19T15:15:58.114656Z","iopub.execute_input":"2022-07-19T15:15:58.115414Z","iopub.status.idle":"2022-07-19T15:32:05.009401Z","shell.execute_reply.started":"2022-07-19T15:15:58.115371Z","shell.execute_reply":"2022-07-19T15:32:05.007883Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"test_x = test_data['text'].copy()\ntest_x = test_x.apply(clean)\ntest_x = tokenizer.texts_to_sequences(test_x)\ntest_x = pad_sequences(test_x, max_len, padding='post')","metadata":{"ExecuteTime":{"end_time":"2022-07-18T14:25:21.956639Z","start_time":"2022-07-18T14:25:21.793077Z"},"execution":{"iopub.status.busy":"2022-07-19T15:32:05.011534Z","iopub.execute_input":"2022-07-19T15:32:05.011965Z","iopub.status.idle":"2022-07-19T15:32:05.221972Z","shell.execute_reply.started":"2022-07-19T15:32:05.011924Z","shell.execute_reply":"2022-07-19T15:32:05.220705Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"prediction","metadata":{}},{"cell_type":"code","source":"test_pred = np.argmax(model.predict(test_x), axis=1)\nprint(test_pred)","metadata":{"ExecuteTime":{"end_time":"2022-07-18T14:25:27.832952Z","start_time":"2022-07-18T14:25:21.987556Z"},"execution":{"iopub.status.busy":"2022-07-19T15:32:05.223790Z","iopub.execute_input":"2022-07-19T15:32:05.224236Z","iopub.status.idle":"2022-07-19T15:32:19.557215Z","shell.execute_reply.started":"2022-07-19T15:32:05.224199Z","shell.execute_reply":"2022-07-19T15:32:19.556185Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"Check the loss ans accuracy","metadata":{}},{"cell_type":"code","source":"history1 = history.history\n\ntrg_loss = history1['loss']\nval_loss = history1['val_loss']\n\ntrg_acc = history1['accuracy']\nval_acc = history1['val_accuracy']\n\nepochs = range(1, len(trg_acc) + 1)\n\n# plot losses and accuracies for training and validation \nfig = plt.figure(figsize=(12,6))\nax = fig.add_subplot(1, 2, 1)\nplt.plot(epochs, trg_loss, marker='o', label='Training Loss')\nplt.plot(epochs, val_loss, marker='x', label='Validation Loss')\nplt.title(\"Training / Validation Loss\")\nax.set_ylabel(\"Loss\")\nax.set_xlabel(\"Epochs\")\nplt.legend(loc='best')\n\nax = fig.add_subplot(1, 2, 2)\nplt.plot(epochs, trg_acc, marker='o', label='Training Accuracy')\nplt.plot(epochs, val_acc, marker='^', label='Validation Accuracy')\nplt.title(\"Training / Validation Accuracy\")\nax.set_ylabel(\"Accuracy\")\nax.set_xlabel(\"Epochs\")\nplt.legend(loc='best')\nplt.show()","metadata":{"ExecuteTime":{"end_time":"2022-07-18T14:28:52.920795Z","start_time":"2022-07-18T14:28:52.529841Z"},"execution":{"iopub.status.busy":"2022-07-19T15:32:19.558638Z","iopub.execute_input":"2022-07-19T15:32:19.559183Z","iopub.status.idle":"2022-07-19T15:32:19.999730Z","shell.execute_reply.started":"2022-07-19T15:32:19.559150Z","shell.execute_reply":"2022-07-19T15:32:19.998942Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"In train data, it is a desirable state in which the loss is small and the accuracy value is high. However, in validation data, it is not convergent and the value is not good.","metadata":{}},{"cell_type":"markdown","source":"**model 2**","metadata":{}},{"cell_type":"markdown","source":"Add Dropout layer","metadata":{}},{"cell_type":"code","source":"epoch_size =10\nbatch_size = 32\nembedding_dim = 16\noptimizer = optimizers.Adam(lr=3e-4)\n\nmodel2 = Sequential([\n    layers.Embedding(vocab_size, embedding_dim, input_length=max_len),\n    layers.Bidirectional(layers.GRU(256, return_sequences=True)),\n    layers.GlobalMaxPool1D(),\n    layers.Dense(64, activation='relu'),\n    layers.Dropout(0.4),\n    layers.Dense(2, activation='sigmoid')\n])\nmodel2.summary()","metadata":{"ExecuteTime":{"end_time":"2022-07-18T14:33:53.354426Z","start_time":"2022-07-18T14:33:53.025308Z"},"execution":{"iopub.status.busy":"2022-07-19T15:32:20.001057Z","iopub.execute_input":"2022-07-19T15:32:20.001572Z","iopub.status.idle":"2022-07-19T15:32:20.468897Z","shell.execute_reply.started":"2022-07-19T15:32:20.001540Z","shell.execute_reply":"2022-07-19T15:32:20.467552Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"model2.compile(loss='sparse_categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])\nhistory = model2.fit(x, y, epochs=epoch_size, validation_split=0.1)","metadata":{"ExecuteTime":{"end_time":"2022-07-18T14:46:12.432698Z","start_time":"2022-07-18T14:33:53.497072Z"},"execution":{"iopub.status.busy":"2022-07-19T15:32:20.470283Z","iopub.execute_input":"2022-07-19T15:32:20.470608Z","iopub.status.idle":"2022-07-19T15:48:29.448521Z","shell.execute_reply.started":"2022-07-19T15:32:20.470579Z","shell.execute_reply":"2022-07-19T15:48:29.447212Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"test_pred = np.argmax(model2.predict(test_x), axis=1)\nprint(test_pred)","metadata":{"ExecuteTime":{"end_time":"2022-07-18T14:46:18.284096Z","start_time":"2022-07-18T14:46:12.464618Z"},"execution":{"iopub.status.busy":"2022-07-19T15:48:29.450476Z","iopub.execute_input":"2022-07-19T15:48:29.450842Z","iopub.status.idle":"2022-07-19T15:48:42.971378Z","shell.execute_reply.started":"2022-07-19T15:48:29.450803Z","shell.execute_reply":"2022-07-19T15:48:42.970435Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"history2 = history.history\n\ntrg_loss = history2['loss']\nval_loss = history2['val_loss']\n\ntrg_acc = history2['accuracy']\nval_acc = history2['val_accuracy']\n\nepochs = range(1, len(trg_acc) + 1)\n\n# plot losses and accuracies for training and validation \nfig = plt.figure(figsize=(12,6))\nax = fig.add_subplot(1, 2, 1)\nplt.plot(epochs, trg_loss, marker='o', label='Training Loss')\nplt.plot(epochs, val_loss, marker='x', label='Validation Loss')\nplt.title(\"Training / Validation Loss\")\nax.set_ylabel(\"Loss\")\nax.set_xlabel(\"Epochs\")\nplt.legend(loc='best')\n\nax = fig.add_subplot(1, 2, 2)\nplt.plot(epochs, trg_acc, marker='o', label='Training Accuracy')\nplt.plot(epochs, val_acc, marker='^', label='Validation Accuracy')\nplt.title(\"Training / Validation Accuracy\")\nax.set_ylabel(\"Accuracy\")\nax.set_xlabel(\"Epochs\")\nplt.legend(loc='best')\nplt.show()","metadata":{"ExecuteTime":{"end_time":"2022-07-18T14:46:18.703051Z","start_time":"2022-07-18T14:46:18.315014Z"},"scrolled":true,"execution":{"iopub.status.busy":"2022-07-19T15:48:42.973051Z","iopub.execute_input":"2022-07-19T15:48:42.973508Z","iopub.status.idle":"2022-07-19T15:48:43.434282Z","shell.execute_reply.started":"2022-07-19T15:48:42.973465Z","shell.execute_reply":"2022-07-19T15:48:43.433389Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"It is improved over model 1, but it is still not convergent and has a good value in validation data.","metadata":{}},{"cell_type":"markdown","source":"**model 3**","metadata":{}},{"cell_type":"markdown","source":"LSTM implementation with basic embedding layer","metadata":{}},{"cell_type":"code","source":"epoch_size =10\nbatch_size = 32\nembedding_dim = 16\noptimizer = optimizers.Adam(lr=3e-4)\n\nmodel3 = Sequential([\n    layers.Embedding(vocab_size, embedding_dim, input_length=max_len, trainable=False),\n    layers.SpatialDropout1D(0.2),\n\n    layers.Bidirectional(layers.LSTM(64, recurrent_dropout=0.5, dropout=0.5, return_sequences=True)),\n    layers.Bidirectional(layers.LSTM(64, recurrent_dropout=0.5, dropout=0.5)),\n\n    layers.Dense(64, activation='relu'),\n    layers.Dense(2, activation='sigmoid')\n])\nmodel3.summary()","metadata":{"ExecuteTime":{"end_time":"2022-07-18T15:11:22.714711Z","start_time":"2022-07-18T15:11:22.408534Z"},"execution":{"iopub.status.busy":"2022-07-19T15:48:43.435662Z","iopub.execute_input":"2022-07-19T15:48:43.436333Z","iopub.status.idle":"2022-07-19T15:48:43.933536Z","shell.execute_reply.started":"2022-07-19T15:48:43.436299Z","shell.execute_reply":"2022-07-19T15:48:43.932108Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"model3.compile(loss='sparse_categorical_crossentropy', optimizer = optimizer, metrics=['accuracy'])\nhistory = model3.fit(x, y, epochs=epoch_size, validation_split=0.1)","metadata":{"ExecuteTime":{"end_time":"2022-07-18T15:23:02.964812Z","start_time":"2022-07-18T15:11:23.705069Z"},"execution":{"iopub.status.busy":"2022-07-19T15:48:43.934985Z","iopub.execute_input":"2022-07-19T15:48:43.935290Z","iopub.status.idle":"2022-07-19T16:35:50.574579Z","shell.execute_reply.started":"2022-07-19T15:48:43.935263Z","shell.execute_reply":"2022-07-19T16:35:50.573641Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"test_pred = np.argmax(model3.predict(test_x), axis=1)\nprint(test_pred)","metadata":{"ExecuteTime":{"end_time":"2022-07-18T15:23:08.560844Z","start_time":"2022-07-18T15:23:02.995729Z"},"execution":{"iopub.status.busy":"2022-07-19T16:35:50.576523Z","iopub.execute_input":"2022-07-19T16:35:50.577083Z","iopub.status.idle":"2022-07-19T16:36:25.382215Z","shell.execute_reply.started":"2022-07-19T16:35:50.577048Z","shell.execute_reply":"2022-07-19T16:36:25.381205Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"history3 = history.history\n\ntrg_loss = history3['loss']\nval_loss = history3['val_loss']\n\ntrg_acc = history3['accuracy']\nval_acc = history3['val_accuracy']\n\nepochs = range(1, len(trg_acc) + 1)\n\n# plot losses and accuracies for training and validation \nfig = plt.figure(figsize=(12,6))\nax = fig.add_subplot(1, 2, 1)\nplt.plot(epochs, trg_loss, marker='o', label='Training Loss')\nplt.plot(epochs, val_loss, marker='x', label='Validation Loss')\nplt.title(\"Training / Validation Loss\")\nax.set_ylabel(\"Loss\")\nax.set_xlabel(\"Epochs\")\nplt.legend(loc='best')\n\nax = fig.add_subplot(1, 2, 2)\nplt.plot(epochs, trg_acc, marker='o', label='Training Accuracy')\nplt.plot(epochs, val_acc, marker='^', label='Validation Accuracy')\nplt.title(\"Training / Validation Accuracy\")\nax.set_ylabel(\"Accuracy\")\nax.set_xlabel(\"Epochs\")\nplt.legend(loc='best')\nplt.show()","metadata":{"ExecuteTime":{"end_time":"2022-07-18T15:23:09.504321Z","start_time":"2022-07-18T15:23:08.591762Z"},"execution":{"iopub.status.busy":"2022-07-19T16:36:25.383625Z","iopub.execute_input":"2022-07-19T16:36:25.384047Z","iopub.status.idle":"2022-07-19T16:36:25.867082Z","shell.execute_reply.started":"2022-07-19T16:36:25.384013Z","shell.execute_reply":"2022-07-19T16:36:25.866173Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"It is improved over model 2, but it is still not convergent and has a good value in validation data.","metadata":{}},{"cell_type":"markdown","source":"**model 4**","metadata":{}},{"cell_type":"markdown","source":"GRU implementation with basic embedding layer and 3 Dense layers","metadata":{}},{"cell_type":"code","source":"epoch_size =10\nbatch_size = 32\nembedding_dim = 16\noptimizer = optimizers.Adam(lr=3e-4)\n\nmodel4 = Sequential([\n    layers.Embedding(vocab_size, embedding_dim, input_length=max_len),\n    layers.Bidirectional(layers.GRU(256, return_sequences=True)),\n    layers.GlobalMaxPool1D(),\n    layers.Dense(128, activation='relu'),\n    layers.Dropout(0.4),\n    layers.Dense(64, activation='relu'),\n    layers.Dropout(0.4),\n    layers.Dense(2, activation='sigmoid')\n])\nmodel4.summary()","metadata":{"ExecuteTime":{"end_time":"2022-07-18T16:12:14.006672Z","start_time":"2022-07-18T16:12:13.661435Z"},"execution":{"iopub.status.busy":"2022-07-19T16:36:25.868206Z","iopub.execute_input":"2022-07-19T16:36:25.868503Z","iopub.status.idle":"2022-07-19T16:36:27.342331Z","shell.execute_reply.started":"2022-07-19T16:36:25.868476Z","shell.execute_reply":"2022-07-19T16:36:27.341201Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"model4.compile(loss='sparse_categorical_crossentropy', optimizer = optimizer, metrics=['accuracy'])\nhistory = model4.fit(x, y, epochs=epoch_size, validation_split=0.2)","metadata":{"ExecuteTime":{"start_time":"2022-07-18T16:12:13.930Z"},"execution":{"iopub.status.busy":"2022-07-19T16:36:27.348381Z","iopub.execute_input":"2022-07-19T16:36:27.348744Z","iopub.status.idle":"2022-07-19T16:51:39.891327Z","shell.execute_reply.started":"2022-07-19T16:36:27.348714Z","shell.execute_reply":"2022-07-19T16:51:39.890123Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"test_pred = np.argmax(model2.predict(test_x), axis=1)\nprint(test_pred)","metadata":{"ExecuteTime":{"start_time":"2022-07-18T16:12:14.194Z"},"execution":{"iopub.status.busy":"2022-07-19T16:51:39.893321Z","iopub.execute_input":"2022-07-19T16:51:39.893968Z","iopub.status.idle":"2022-07-19T16:51:52.854605Z","shell.execute_reply.started":"2022-07-19T16:51:39.893892Z","shell.execute_reply":"2022-07-19T16:51:52.853708Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"history4 = history.history\n\ntrg_loss = history4['loss']\nval_loss = history4['val_loss']\n\ntrg_acc = history4['accuracy']\nval_acc = history4['val_accuracy']\n\nepochs = range(1, len(trg_acc) + 1)\n\n# plot losses and accuracies for training and validation \nfig = plt.figure(figsize=(12,6))\nax = fig.add_subplot(1, 2, 1)\nplt.plot(epochs, trg_loss, marker='o', label='Training Loss')\nplt.plot(epochs, val_loss, marker='x', label='Validation Loss')\nplt.title(\"Training / Validation Loss\")\nax.set_ylabel(\"Loss\")\nax.set_xlabel(\"Epochs\")\nplt.legend(loc='best')\n\nax = fig.add_subplot(1, 2, 2)\nplt.plot(epochs, trg_acc, marker='o', label='Training Accuracy')\nplt.plot(epochs, val_acc, marker='^', label='Validation Accuracy')\nplt.title(\"Training / Validation Accuracy\")\nax.set_ylabel(\"Accuracy\")\nax.set_xlabel(\"Epochs\")\nplt.legend(loc='best')\nplt.show()","metadata":{"ExecuteTime":{"start_time":"2022-07-18T16:12:14.595Z"},"execution":{"iopub.status.busy":"2022-07-19T16:51:52.856289Z","iopub.execute_input":"2022-07-19T16:51:52.856928Z","iopub.status.idle":"2022-07-19T16:51:53.312715Z","shell.execute_reply.started":"2022-07-19T16:51:52.856875Z","shell.execute_reply":"2022-07-19T16:51:53.311476Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"The loss value is high and the accuracy is significantly different from the train result.","metadata":{}},{"cell_type":"markdown","source":"**model 5**","metadata":{}},{"cell_type":"markdown","source":"GloVe embedded LSTM, RNN and add BatchNormalization","metadata":{}},{"cell_type":"code","source":"embeddings_dictionary = dict()\nembedding_dim = 100\nglove_file = open('../input/glove6b100dtxt/glove.6B.100d.txt', encoding='UTF8')\nfor line in glove_file:\n    records = line.split()\n    word = records[0]\n    vector_dimensions = np.asarray(records[1:], dtype='float32')\n    embeddings_dictionary [word] = vector_dimensions\nglove_file.close()","metadata":{"execution":{"iopub.status.busy":"2022-07-19T16:51:53.314380Z","iopub.execute_input":"2022-07-19T16:51:53.314750Z","iopub.status.idle":"2022-07-19T16:52:06.700328Z","shell.execute_reply.started":"2022-07-19T16:51:53.314717Z","shell.execute_reply":"2022-07-19T16:52:06.698856Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"embedding_matrix = np.zeros((vocab_size, embedding_dim))\nfor word, index in tokenizer.word_index.items():\n    embedding_vector = embeddings_dictionary.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[index] = embedding_vector","metadata":{"execution":{"iopub.status.busy":"2022-07-19T16:52:06.702429Z","iopub.execute_input":"2022-07-19T16:52:06.702794Z","iopub.status.idle":"2022-07-19T16:52:06.754608Z","shell.execute_reply.started":"2022-07-19T16:52:06.702762Z","shell.execute_reply":"2022-07-19T16:52:06.753367Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"epoch_size =10\nbatch_size = 32\n\nmodel5 = Sequential([\n    layers.Embedding(input_dim=embedding_matrix.shape[0], \n                        output_dim=embedding_matrix.shape[1], \n                        weights = [embedding_matrix]\n                        ),\n    layers.Bidirectional(LSTM(64, return_sequences = True, recurrent_dropout=0.2)),\n    layers.GlobalMaxPool1D(),\n    layers.BatchNormalization(),\n    layers.Dropout(0.5),\n    layers.Dense(128, activation='relu'),\n    layers.Dropout(0.5),\n    layers.Dense(64, activation='relu'),\n    layers.Dropout(0.5),\n    layers.Dense(1, activation='sigmoid')\n])\nmodel5.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-19T16:52:06.756131Z","iopub.execute_input":"2022-07-19T16:52:06.756488Z","iopub.status.idle":"2022-07-19T16:52:07.059840Z","shell.execute_reply.started":"2022-07-19T16:52:06.756456Z","shell.execute_reply":"2022-07-19T16:52:07.058538Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"model5.compile(loss='binary_crossentropy', optimizer = RMSprop(learning_rate=0.0001), metrics=['accuracy'])\nhistory5 = model5.fit(x, y, epochs=epoch_size, validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2022-07-19T16:52:07.061784Z","iopub.execute_input":"2022-07-19T16:52:07.062247Z","iopub.status.idle":"2022-07-19T17:16:36.025660Z","shell.execute_reply.started":"2022-07-19T16:52:07.062200Z","shell.execute_reply":"2022-07-19T17:16:36.024214Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"test_pred = np.argmax(model5.predict(test_x), axis=1)\nprint(test_pred)","metadata":{"execution":{"iopub.status.busy":"2022-07-19T17:16:36.028188Z","iopub.execute_input":"2022-07-19T17:16:36.028587Z","iopub.status.idle":"2022-07-19T17:16:54.810320Z","shell.execute_reply.started":"2022-07-19T17:16:36.028550Z","shell.execute_reply":"2022-07-19T17:16:54.809200Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"history = history5.history\n\ntrg_loss = history['loss']\nval_loss = history['val_loss']\n\ntrg_acc = history['accuracy']\nval_acc = history['val_accuracy']\n\nepochs = range(1, len(trg_acc) + 1)\n\n# plot losses and accuracies for training and validation \nfig = plt.figure(figsize=(12,6))\nax = fig.add_subplot(1, 2, 1)\nplt.plot(epochs, trg_loss, marker='o', label='Training Loss')\nplt.plot(epochs, val_loss, marker='x', label='Validation Loss')\nplt.title(\"Training / Validation Loss\")\nax.set_ylabel(\"Loss\")\nax.set_xlabel(\"Epochs\")\nplt.legend(loc='best')\n\nax = fig.add_subplot(1, 2, 2)\nplt.plot(epochs, trg_acc, marker='o', label='Training Accuracy')\nplt.plot(epochs, val_acc, marker='^', label='Validation Accuracy')\nplt.title(\"Training / Validation Accuracy\")\nax.set_ylabel(\"Accuracy\")\nax.set_xlabel(\"Epochs\")\nplt.legend(loc='best')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-19T17:16:54.812050Z","iopub.execute_input":"2022-07-19T17:16:54.812470Z","iopub.status.idle":"2022-07-19T17:16:55.262865Z","shell.execute_reply.started":"2022-07-19T17:16:54.812426Z","shell.execute_reply":"2022-07-19T17:16:55.261837Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"Both loss and accuracy values converge and the difference from the train data results tends to decrease.\nHowever, the loss value is still large and the accumulation value seems to need further improvement.","metadata":{}},{"cell_type":"markdown","source":"**model 6**","metadata":{}},{"cell_type":"markdown","source":"GloVe embedded GRU","metadata":{}},{"cell_type":"code","source":"epoch_size =10\nbatch_size = 32\n\nmodel6 = Sequential([\n    layers.Embedding(input_dim=embedding_matrix.shape[0], \n                        output_dim=embedding_matrix.shape[1], \n                        weights = [embedding_matrix]\n                        ),\n    layers.Bidirectional(layers.GRU(256, return_sequences=True)),\n    layers.GlobalMaxPool1D(),\n    layers.Dense(64, activation='relu'),\n    layers.Dropout(0.4),\n    layers.Dense(2, activation='sigmoid')\n])\nmodel6.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-19T17:16:55.264762Z","iopub.execute_input":"2022-07-19T17:16:55.266306Z","iopub.status.idle":"2022-07-19T17:16:55.772788Z","shell.execute_reply.started":"2022-07-19T17:16:55.266236Z","shell.execute_reply":"2022-07-19T17:16:55.771364Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"model6.compile(loss='sparse_categorical_crossentropy', optimizer = RMSprop(learning_rate=0.0001), metrics=['accuracy'])\nhistory6 = model6.fit(x, y, epochs=epoch_size, validation_split=0.1)","metadata":{"execution":{"iopub.status.busy":"2022-07-19T17:16:55.774853Z","iopub.execute_input":"2022-07-19T17:16:55.775294Z","iopub.status.idle":"2022-07-19T17:35:29.184446Z","shell.execute_reply.started":"2022-07-19T17:16:55.775258Z","shell.execute_reply":"2022-07-19T17:35:29.183508Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"test_pred = np.argmax(model6.predict(test_x), axis=1)\nprint(test_pred)","metadata":{"execution":{"iopub.status.busy":"2022-07-19T17:35:29.185680Z","iopub.execute_input":"2022-07-19T17:35:29.186001Z","iopub.status.idle":"2022-07-19T17:35:45.101117Z","shell.execute_reply.started":"2022-07-19T17:35:29.185974Z","shell.execute_reply":"2022-07-19T17:35:45.100253Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"history = history6.history\n\ntrg_loss = history['loss']\nval_loss = history['val_loss']\n\ntrg_acc = history['accuracy']\nval_acc = history['val_accuracy']\n\nepochs = range(1, len(trg_acc) + 1)\n\n# plot losses and accuracies for training and validation \nfig = plt.figure(figsize=(12,6))\nax = fig.add_subplot(1, 2, 1)\nplt.plot(epochs, trg_loss, marker='o', label='Training Loss')\nplt.plot(epochs, val_loss, marker='x', label='Validation Loss')\nplt.title(\"Training / Validation Loss\")\nax.set_ylabel(\"Loss\")\nax.set_xlabel(\"Epochs\")\nplt.legend(loc='best')\n\nax = fig.add_subplot(1, 2, 2)\nplt.plot(epochs, trg_acc, marker='o', label='Training Accuracy')\nplt.plot(epochs, val_acc, marker='^', label='Validation Accuracy')\nplt.title(\"Training / Validation Accuracy\")\nax.set_ylabel(\"Accuracy\")\nax.set_xlabel(\"Epochs\")\nplt.legend(loc='best')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-19T17:35:45.102403Z","iopub.execute_input":"2022-07-19T17:35:45.102724Z","iopub.status.idle":"2022-07-19T17:35:45.549368Z","shell.execute_reply.started":"2022-07-19T17:35:45.102697Z","shell.execute_reply":"2022-07-19T17:35:45.548139Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"Both loss and accuracy values were improved in the desired direction.","metadata":{}},{"cell_type":"markdown","source":"# 6. Create a submission","metadata":{}},{"cell_type":"markdown","source":"Generate the results as a csv file.","metadata":{}},{"cell_type":"code","source":"submission = pd.DataFrame({'id':test_data['id'], 'target':test_pred})\nsubmission.to_csv('submission.csv', index=False)","metadata":{"ExecuteTime":{"end_time":"2022-07-18T14:14:55.099204Z","start_time":"2022-07-18T14:10:26.552Z"},"execution":{"iopub.status.busy":"2022-07-19T17:35:45.551195Z","iopub.execute_input":"2022-07-19T17:35:45.551518Z","iopub.status.idle":"2022-07-19T17:35:45.567173Z","shell.execute_reply.started":"2022-07-19T17:35:45.551489Z","shell.execute_reply":"2022-07-19T17:35:45.565764Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}